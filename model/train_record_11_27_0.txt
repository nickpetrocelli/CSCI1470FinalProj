Starting data preprocessing.
Finished preprocessing. Starting training.
0 / 5220 LOSS : 149.0138702392578
100 / 5220 LOSS : 676.3797607421875
200 / 5220 LOSS : 91.67992401123047
300 / 5220 LOSS : 31.501258850097656
400 / 5220 LOSS : 17.297122955322266
500 / 5220 LOSS : 33.73397445678711
600 / 5220 LOSS : 56.54878234863281
700 / 5220 LOSS : 75.15757751464844
800 / 5220 LOSS : 114.66753387451172
900 / 5220 LOSS : 142.5636444091797
1000 / 5220 LOSS : 138.0336151123047
1100 / 5220 LOSS : 180.66929626464844
1200 / 5220 LOSS : 168.98031616210938
1300 / 5220 LOSS : 202.6253204345703
1400 / 5220 LOSS : 182.03494262695312
1500 / 5220 LOSS : 178.06942749023438
1600 / 5220 LOSS : 222.91815185546875
1700 / 5220 LOSS : 179.41427612304688
1800 / 5220 LOSS : 143.0607452392578
1900 / 5220 LOSS : 136.47418212890625
2000 / 5220 LOSS : 107.45942687988281
2100 / 5220 LOSS : 115.46464538574219
2200 / 5220 LOSS : 112.56231689453125
2300 / 5220 LOSS : 121.27854919433594
2400 / 5220 LOSS : 124.86881256103516
2500 / 5220 LOSS : 124.59629821777344
2600 / 5220 LOSS : 138.81640625
2700 / 5220 LOSS : 117.51681518554688
2800 / 5220 LOSS : 105.35974884033203
2900 / 5220 LOSS : 130.91348266601562
3000 / 5220 LOSS : 95.54029846191406
3100 / 5220 LOSS : 93.55635070800781
3200 / 5220 LOSS : 87.20882415771484
3300 / 5220 LOSS : 76.20272827148438
3400 / 5220 LOSS : 73.88679504394531
3500 / 5220 LOSS : 66.27262115478516
3600 / 5220 LOSS : 73.8401107788086
3700 / 5220 LOSS : 59.17741394042969
3800 / 5220 LOSS : 59.56061553955078
3900 / 5220 LOSS : 67.22805786132812
4000 / 5220 LOSS : 73.9863052368164
4100 / 5220 LOSS : 64.79177856445312
4200 / 5220 LOSS : 66.36190032958984
4300 / 5220 LOSS : 72.84815979003906
4400 / 5220 LOSS : 53.97509002685547
4500 / 5220 LOSS : 62.02714538574219
4600 / 5220 LOSS : 56.1365852355957
4700 / 5220 LOSS : 58.491817474365234
4800 / 5220 LOSS : 60.366455078125
4900 / 5220 LOSS : 53.26506042480469
5000 / 5220 LOSS : 53.746192932128906
5100 / 5220 LOSS : 58.23106384277344
5200 / 5220 LOSS : 13.071255683898926
Testing...
tf.Tensor(-158974.14, shape=(), dtype=float32)
tf.Tensor(-156208.53, shape=(), dtype=float32)
tf.Tensor(-157408.84, shape=(), dtype=float32)
tf.Tensor(-157745.19, shape=(), dtype=float32)
tf.Tensor(-151764.19, shape=(), dtype=float32)
tf.Tensor(-156641.69, shape=(), dtype=float32)
tf.Tensor(-156473.69, shape=(), dtype=float32)
tf.Tensor(-158017.9, shape=(), dtype=float32)
tf.Tensor(-153718.56, shape=(), dtype=float32)
tf.Tensor(-154633.34, shape=(), dtype=float32)
tf.Tensor(-158379.16, shape=(), dtype=float32)
tf.Tensor(-160954.23, shape=(), dtype=float32)
tf.Tensor(-159059.66, shape=(), dtype=float32)
tf.Tensor(-157021.12, shape=(), dtype=float32)
tf.Tensor(-158837.12, shape=(), dtype=float32)
tf.Tensor(-160185.42, shape=(), dtype=float32)
tf.Tensor(-156696.25, shape=(), dtype=float32)
tf.Tensor(-159427.12, shape=(), dtype=float32)
tf.Tensor(-157862.45, shape=(), dtype=float32)
tf.Tensor(-161333.03, shape=(), dtype=float32)
tf.Tensor(-160698.28, shape=(), dtype=float32)
tf.Tensor(-161603.6, shape=(), dtype=float32)
tf.Tensor(-60936.332, shape=(), dtype=float32)
FINAL AVERAGE TEST LOSS: -153677.375
