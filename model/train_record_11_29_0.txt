Starting data preprocessing.
Finished preprocessing. Starting training.
0 / 5220 LOSS : 235.08602905273438
100 / 5220 LOSS : 1052.962646484375
200 / 5220 LOSS : 107.2230224609375
300 / 5220 LOSS : 30.523014068603516
400 / 5220 LOSS : 17.102092742919922
500 / 5220 LOSS : 30.911598205566406
600 / 5220 LOSS : 58.88274383544922
700 / 5220 LOSS : 93.39570617675781
800 / 5220 LOSS : 123.10169982910156
900 / 5220 LOSS : 163.3035125732422
1000 / 5220 LOSS : 167.5738525390625
1100 / 5220 LOSS : 209.9124298095703
1200 / 5220 LOSS : 242.70162963867188
1300 / 5220 LOSS : 218.64105224609375
1400 / 5220 LOSS : 253.168212890625
1500 / 5220 LOSS : 231.74386596679688
1600 / 5220 LOSS : 214.55718994140625
1700 / 5220 LOSS : 167.1068572998047
1800 / 5220 LOSS : 127.47706604003906
1900 / 5220 LOSS : 147.55657958984375
2000 / 5220 LOSS : 146.49302673339844
2100 / 5220 LOSS : 131.99676513671875
2200 / 5220 LOSS : 126.25858306884766
2300 / 5220 LOSS : 114.59196472167969
2400 / 5220 LOSS : 97.28208923339844
2500 / 5220 LOSS : 84.48434448242188
2600 / 5220 LOSS : 68.37539672851562
2700 / 5220 LOSS : 70.4654541015625
2800 / 5220 LOSS : 61.914424896240234
2900 / 5220 LOSS : 70.82748413085938
3000 / 5220 LOSS : 61.789756774902344
3100 / 5220 LOSS : 60.1722526550293
3200 / 5220 LOSS : 62.324989318847656
3300 / 5220 LOSS : 60.67595291137695
3400 / 5220 LOSS : 61.624488830566406
3500 / 5220 LOSS : 56.99498748779297
3600 / 5220 LOSS : 70.65518951416016
3700 / 5220 LOSS : 60.517120361328125
3800 / 5220 LOSS : 59.8382568359375
3900 / 5220 LOSS : 61.891197204589844
4000 / 5220 LOSS : 50.001705169677734
4100 / 5220 LOSS : 51.38963317871094
4200 / 5220 LOSS : 57.52851867675781
4300 / 5220 LOSS : 67.59646606445312
4400 / 5220 LOSS : 70.66581726074219
4500 / 5220 LOSS : 69.67581939697266
4600 / 5220 LOSS : 52.32439422607422
4700 / 5220 LOSS : 39.53562927246094
4800 / 5220 LOSS : 67.38388061523438
4900 / 5220 LOSS : 89.69715118408203
5000 / 5220 LOSS : 114.68714904785156
5100 / 5220 LOSS : 126.30596923828125
5200 / 5220 LOSS : 27.08993148803711
Testing...
tf.Tensor(184359.44, shape=(), dtype=float32)
tf.Tensor(180782.4, shape=(), dtype=float32)
tf.Tensor(182637.72, shape=(), dtype=float32)
tf.Tensor(183896.3, shape=(), dtype=float32)
tf.Tensor(176905.5, shape=(), dtype=float32)
tf.Tensor(180685.14, shape=(), dtype=float32)
tf.Tensor(182117.28, shape=(), dtype=float32)
tf.Tensor(183084.06, shape=(), dtype=float32)
tf.Tensor(179252.16, shape=(), dtype=float32)
tf.Tensor(178219.22, shape=(), dtype=float32)
tf.Tensor(183195.42, shape=(), dtype=float32)
tf.Tensor(185734.25, shape=(), dtype=float32)
tf.Tensor(183748.45, shape=(), dtype=float32)
tf.Tensor(181685.1, shape=(), dtype=float32)
tf.Tensor(183047.12, shape=(), dtype=float32)
tf.Tensor(183984.72, shape=(), dtype=float32)
tf.Tensor(182042.4, shape=(), dtype=float32)
tf.Tensor(184256.12, shape=(), dtype=float32)
tf.Tensor(182452.1, shape=(), dtype=float32)
tf.Tensor(185233.62, shape=(), dtype=float32)
tf.Tensor(186139.27, shape=(), dtype=float32)
tf.Tensor(186319.22, shape=(), dtype=float32)
tf.Tensor(70438.22, shape=(), dtype=float32)
FINAL AVERAGE TEST LOSS: 177835.453125
